# HW1 George W Nakhla


Package installs:
```{r}
#install.packages("MPV")
library("MPV")
library("knitr")
```

## Q1: Question 2.3. Table B.2 presents data collected during a solar energy project at Georgia Tech

### a) Fit a simple linear regression model relating total heat flux y (kilowatts) to the radial deflection of the deflected rays x4 (milliradians).
```{r}
solarData <- table.b2
fit <- lm( y ~ x4, data = solarData)
lm( y ~ x4, data = solarData)
plot(solarData$x4, solarData$y, 
     xlab = "radial deflection of deflected rays (x4)", 
     ylab = "total heat flux (y)",
     main = "Model")
abline(fit)
```


So we have the equation y = 607.1 -21.4(x4) as plotted above. This is a negative relationship, and describes that for each one unit increase in x4, we can expect a 21.4 unit decrease of y. The 607.1 can be interpreted as a radial deflection of 0, we can expect a heat flux to be 607.1


### b) Construct the analysis-of-variance table and test for significance of regression.
```{r}
# here, we want to conduct a hypothesis test for our regression coefficient. Our H0 (null hypothesis) is that there is no relationship between x4 and y (B1 is 0). The alternative hypothesis is that B1 is non 0. In this case, the previous graph more strongly suggests that B1 is less than 0, or an inverse relationship.
summary(fit)
anova(fit)
```

72.05% of the variance in y is explained by x4
<br>
The p value of the F statistic is extremely low (5.935e-09), indicating that the overall model is significant and that the slope (B1) is not zero. We reject the initial hypothesis in favor of the alternative.
<br>

### c) Find a 99% CI on the slope.
```{r}
conf_interval <- confint(fit, level = 0.99)
print(conf_interval)

```
After running this and seeing the results, we can say that we are 99% certain that the true slope of the regression (beta1) falls
between:
<br>
(-28.50995, -14.29497)

### d) Calculate R^2^
```{r}
#previously printed the summary, but this will show only r^2
summary(fit)$r.squared
```
Again, we can say that 72.05% of the variance in y is explained by x4 based on this r^2 value

### e) Find a 95% CI on the mean heat flux when the radial deflection is 16.5 milliradians.

```{r}
# Define the new data point
new_data <- data.frame(x4 = 16.5)

# Predict the mean heat flux and obtain confidence intervals
prediction <- predict(fit, newdata = new_data, interval = "confidence", level = 0.95)

# Print the prediction and confidence intervals
print(prediction)
```

We see that based on the model, we get an expected heat flux of 253.9627 kilowatts. We are 95% certain that the true expected heat flux would be between:
<br>
(249.1468, 258.7787)

## Q2: Question 2.6. Table B.4 presents data for 27 houses sold in Erie, Pennsylvania.

### a) Fit a simple linear regression model relating selling price of the house to the current taxes ( x1 ).
```{r}
houseData <- table.b4
lm(y ~ x1, data = houseData)
homeFit <- lm(y ~ x1, data = houseData)
plot(houseData$x1,houseData$y,
     xlab = "Current Taxes",
     ylab = "Selling Price",
     main = "Current Taxes vs. House Selling Price")
abline(homeFit)
```

Based on the regression, we see that the equation of the model plotted above is: y = 13.320 + 3.324(x1). This suggests that for each 1 unit increase in x1, we can expect a 3.324 increase in y. The interpretation of 13.320 is that at a tax cost of 0 (which in this case is unrealistic), we can expect a house selling price of 13.320.

### b) Test for significance of regression.
```{r}
# here, we want to conduct a hypothesis test for our regression coefficient. Our H0 (null hypothesis) is that there is no relationship between x1 and y (B1 is 0). The alternative hypothesis is that B1 is non 0. In this case, the previous graph more strongly suggests that B1 is greater than 0, or a positive relationship.
summary(homeFit)
```
At a p-value of 2.051e-08, we can confidently reject the null hypothesis in favor of the alternate. This is evidence that there is a non-zero relationship between tax cost and house selling price.

### c)  Calculate R^2^
```{r}
summary(homeFit)$r.squared
```
We can say that 76.73344% of the variance in y is explained by x2 based on this r^2^ value

### d) Find a 95% CI on the slope.
```{r}
confint(homeFit, level = 0.95)
```
We are 95% certain that the true slope of B1 lies between:
(2.514988, 4.133754)

### e) Find a 95% CI on the mean selling price of a house for which the current taxes are $750.
```{r}
# NOTE: x1 is documented to be represented in thousands, so we will use 750/1000 = .75
new_data <- data.frame(x1 = .75)
predict(homeFit, newdata = new_data, interval = "confidence", level = 0.95)

```
NOTE: All in thousands
The prediction model expresses that we can expect a house selling price of 15.81346 for a tax cost of .75. We are 95% certain that the true selling price for a house with a .75 tax cost is:
<br>
(11.06792, 20.55899)

## Q3: Question 2.7. The purity of oxygen produced by a fractional distillation process is thought to be related to the percentage of hydrocarbons in the main condenser of the processing unit.

### a) Fit a simple linear regression model to the data.
```{r}
chemData <- p2.7
chemFit = lm(purity ~ hydro, data = chemData)
print(chemFit)
plot(chemData$hydro, chemData$purity,
     xlab = "Hydrocarbons",
     ylab = "Purity",
     main = "Hydrocarbons vs. O2 Purity")
abline(chemFit)
```
The formula describing the model is y = 77.86 + 11.80β1, where 77.86 represents the oxygen purity at a 0 percent hydrocarbon concentration and 11.80 represents the expected units of increase of y for every unit of x.

### b) Test the hypothesis H0:β1 = 0.
```{r}
# we can set up our null hypothesis to be: H0:β1 = 0
# Our alternative hypothesis, H_a is β1 != 0
# since no alpha value is given, we can assume to have a two tailed test with an alpha of .1
# we can conduct this with a hypothesis t test. we can find the p value by calling:
summary(chemFit)
```
Since our p-value is 0.003291 which is less than our one tailed alpha of .05, we can reject the null in favor of the alternate. We have sufficient evidence to claim that β1 != 0.

### c) c. Calculate R^2^
```{r}
summary(chemFit)$r.squared
```
We get an R^2^ value of 0.3891224. This means that 38.91224% of the variability in the oxygen purity can be attributed to the percentage of hydrocarbons in the main condenser.


### d) Find a 95% CI on the slope.
```{r}
confint(chemFit, level = 0.95)
```
We are 95% certain that the true slope (β1) falls between:
(4.479066, 19.12299)

### e) Find a 95% CI on the mean purity when the hydrocarbon percentage is 1.00.
```{r}
new_data = data.frame(hydro = 1.00)
predict(chemFit, newdata = new_data, interval = "confidence", level = 0.95)
```
The model predicts that at a hydrocarbon percentage of 1.00, the purity will be at 89.66%. We are 95% certain that the true purity will be between (in percent):
(87.51017, 91.81845)


## Q4: Question 2.8. Consider the oxygen plant data in Problem 2.7 and assume that purity and hydrocarbon percentage are jointly normally distributed random variables.

### a) What is the correlation between oxygen purity and hydrocarbon percentage?
```{r}
# we are using the same data as Q3

# two ways to calculate it!
cor(chemData$purity, chemData$hydro)
sqrt(summary(chemFit)$r.squared)
```
The correlation coefficient (r) is equal to 0.6237968. This indicates a moderately strong positive linear relationship between the hydrocarbon % and the purity of the oxygen.

### b) Test the hypothesis that ρ = 0.
```{r}
# can assume alpha of .1
# H0 :ρ = 0; our alternate hypothesis is that ρ != 0. We can conduct Pearson's product moment correlation by calling:
cor.test(chemData$purity, chemData$hydro)
# and checking the p-value
```
We get a p value of .003 which is less than our alpha, and as such gives us sufficient evidence to reject H0 in favor of our alternate.

### c) Construct a 95% CI for ρ.
```{r}
# can call the same function as before as it also gives us a 95% CI
cor.test(chemData$purity, chemData$hydro)
```
We see that running this gives us a 95% CI of (0.2503961, 0.8356439). The interpretation of this is that we are 95% certain that the true value of ρ lies between:
<br>
(0.2503961, 0.8356439)
